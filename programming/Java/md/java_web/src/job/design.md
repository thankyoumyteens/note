# 你在项目中是怎么设计定时任务和失败补偿机制的？

在XX系统中，有大量的定期数据同步任务(数据库同步到ES、定时统计注册用户量等)，我们使用 XXL-JOB 做统一调度，主要注意了几点：

1. 任务拆分:
   - 避免单个大任务处理全部数据，改为按类型、时间或分片 ID 拆分成多个小任务；
   - 使用 XXL-JOB 的分片广播功能，让多个执行器实例并行处理不同片区的数据。
2. 幂等设计:
   - 每个任务执行都会关联一个「业务批次号」，在数据库里记录执行状态；
   - 处理前先检查该批次是否已经执行过，或者局部执行过，避免重复写入；
   - 更新操作采用「upsert」或乐观锁，保证重复执行不会产生错误副作用。
3. 失败补偿:
   - 任务执行过程中，针对每条数据记录处理结果（成功 / 失败 + 失败原因）；
   - 对失败记录按一定规则（比如网络问题、下游超时）进行自动重试，超过重试次数后告警人工处理；
   - XXL-JOB 本身也有失败告警通知（邮件 / 钉钉），结合监控系统，能及时发现异常。

## 深入追问

### 你们为什么要用调度中心，而不是各服务自己写 @Scheduled？整个设计是怎样的？

我们那套系统里有很多周期性任务，比如：

- 把数据库里的业务数据增量同步到 ES；
- 定时统计注册用户量、活跃度等运营指标；

一开始如果每个服务自己用 @Scheduled，会有几个问题：

- 调度分散，不好统一管理和观察；
- 没有统一的失败告警和重试策略；
- 很难做分片并行和手动触发 / 停止等运维操作。

所以我们后来统一接了 XXL-JOB，实现方式大致是：

- 以 XXL-JOB 作为统一调度中心：
  - 统一配置 CRON；
  - 控制任务启停、手动触发；
  - 记录任务执行日志、基本重试；
- 各个业务服务作为执行器：
  - 实现对应的 JobHandler；
  - 在任务内部做更细力度的：
    - 任务拆分
    - 幂等控制
    - 失败补偿、重试和告警。

这样一来，调度和业务逻辑是解耦的，排查问题和运维也比较集中。

### 像数据库同步到 ES 这种任务，数据量通常比较大。你们是怎么做任务拆分的？有没有用到 XXL-JOB 的分片能力？

有的，这块我们其实做了两层拆分，避免出现“一个超大任务扫全库、拖很久”的情况。

1. 业务维度 / 时间维度拆分
   - 先从业务上把任务拆“小”
     - 按任务类型拆：
       - 比如用户数据同步、公共查询数据同步、统计注册用户量，这些是不同的 XXL-JOB 任务；
     - 对同一类任务，再按时间范围拆：
       - 比如“同步上一小时的增量数据”、“统计昨日注册用户数”。
   - 这样每个任务的处理范围都是可控的，单个任务执行时间不会太长，出问题时回查也更清晰。
2. 分片广播：让多个实例并行执行
   - 在单个任务内部，我们会用 XXL-JOB 的分片广播功能做并行处理：
     - 在 XXL-JOB 上配置任务为分片广播模式，比如 8 片；
     - 每次调度时，XXL-JOB 会对所有在线执行器广播，并携带：
       - 当前分片索引：shardIndex
       - 分片总数：shardTotal
     - 在 JobHandler 里，我们根据 shardIndex / shardTotal 按某种规则分片数据：
       - 比如对用户 ID 取模：user_id % shardTotal == shardIndex；
       - 或者按分库分表 / 地区 / 自增 ID 区间来分不同片区。
   - 这样就可以做到：
     - 多个执行器实例并行处理不同的数据分片；
     - 把单个任务执行时间控制在一个合理范围（方便监控、超时处理）；
     - 总体吞吐量提升的同时，不会让某一个实例成为性能瓶颈。
     - 借助分片并行，水平扩展同步能力，避免大批量同步时拖慢整个系统。

### 定时任务经常会遇到“任务失败后重试”或者“调度重复触发”的情况，你们是怎么做幂等的？你刚才说的业务批次号具体怎么用？

对，我们这块是按“批次”来做幂等控制的，主要有三点：

1. 业务批次号 + 执行状态记录
   - 每次任务执行都会生成一个业务批次号，比如：
     - 按任务类型 + 时间窗口拼接：`SYNC_USER_2026-01-31T10:00`；
   - 在数据库维护一张任务批次表，记录：
     - 任务类型
     - 执行时间窗口
     - 批次号
     - 当前状态（待执行、执行中、部分成功、成功、失败）
     - 已处理数量、失败数量等统计信息。
   - 这样有几个好处：
     - 同一个时间窗口如果被重复调度，我们能通过批次号快速识别出来；
     - 后续做失败补偿时，可以精准定位到某一次批次的失败记录。
2. 任务正式处理前会对这个批次做一次幂等检查：
   - 如果发现这个批次已经是“成功”状态：
     - 说明之前已经完整执行过，本次直接跳过；
   - 如果是“部分成功 / 执行中”：
     - 可以只拉取“未处理或失败”的记录，做局部补偿。
   - 这样即使 XXL-JOB 重复触发、或者我们手工重跑某个时间段的任务，也不会出现重复写入 / 统计翻倍的问题。
3. 在落库或写 ES 的时候，我们会再做一层幂等，常用几种方式：
   - 使用 upsert 语义（插入或更新）：
     - 比如数据库用 `INSERT ... ON DUPLICATE KEY UPDATE`；
     - ES 用 index / update，以业务主键作为 `_id`；
   - 对关键表用乐观锁字段（version 或时间戳）：
     - 更新时带上版本，如果版本不一致就拒绝更新；
   - 有些统计类任务，我们是先删后插 / 覆盖写：
     - 比如“统计某天的注册用户数”，按日期维度整行覆盖。

### 你刚才说有失败补偿机制，那这块能详细讲讲吗？你们是怎么记录失败、怎么重试、怎么跟告警结合的？只用 XXL-JOB 自己的失败重试够不够？

我们没有只依赖 XXL-JOB 自带的“失败重试”，它更多是任务级别的重试；对我们这种“批量数据处理”的场景，还需要记录到单条数据的处理结果，才能做精准补偿。

具体是三层：

1. 单条记录处理结果落库
   - 在任务执行过程中，对每一条数据我们都会记录处理结果；
   - 有一张任务明细表，字段包括：
     - 批次号
     - 业务主键 ID（比如 user_id、xxx_id）
     - 处理状态（成功 / 失败）
     - 失败原因（错误码 + 错误信息）
     - 重试次数
     - 最后处理时间等。
   - 这样可以：
     - 清晰看到本次批次总共处理了多少条、成功多少、失败多少；
     - 后续可以只针对“失败的记录”做补偿，不用全量重跑。
2. 自动重试策略（规则 + 次数控制）
   - 对于失败的记录，我们会按失败原因分类处理：
     - 如果是网络抖动、下游超时、临时性异常：
       - 自动进入重试队列；
       - 设置最大重试次数，比如 3 次；
       - 重试之间可以加一个退避策略（如延迟 1 分钟 / 5 分钟）；
     - 如果是业务数据问题（比如字段非法、状态不合法）：
       - 标记为“永久失败”，不做自动重试，直接进入告警和人工处理流程。
   - 这样保证：
     - 对“偶发错误”可以自动恢复；
     - 对“确定性错误”不会无限重试、浪费资源。
3. 告警与人工补偿
   - 补偿策略之外，我们还有两类告警：
     - XXL-JOB 自带任务级告警：
       - 任务整体执行失败、超时，触发邮件 / 钉钉通知；
       - 适合发现“整个任务挂了 / 执行异常”的情况。
     - 我们自己的业务告警：
       - 如果某个批次的失败率超过阈值（比如失败率 > 5%），会上报警告；
       - 或者某条记录自动重试多次仍失败，也会单独告警。
   - 人工处理方面，我们支持：
     - 运维 / 开发人员在管理后台查看某个批次的失败明细；
     - 支持按“批次号”或“单条业务 ID”触发单独重跑 / 局部重跑；
     - 这样不需要每次都重跑整个任务。
