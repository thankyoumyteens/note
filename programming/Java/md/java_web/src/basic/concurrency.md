# 说一个你在实际项目中用到多线程/并发控制的场景，怎么设计的？

在 XX 系统里有个场景是 **为模型推断出的疑似窃电行为批量生成并下发工单**，一次任务可能涉及几万条数据，如果串行处理，接口响应会非常慢，还可能导致网关超时。

我的做法是：

1. 在业务上把这个操作拆成两部分：
   - 前端只发起“创建批量任务”，接口快速返回一个任务 ID，前端可以拿这个任务 ID 去查进度；
   - 真实的工单生成与下发放到后台异步执行。
2. 后台通过自定义线程池处理任务，合理设置 corePoolSize / maxPoolSize / 有界队列，避免把内存打爆。
3. 对于任务执行结果，通过状态字段 + 定时任务做兜底检查，如果任务长时间未完成会有告警并重试。

---

## 深入追问

### 你说你用了线程池，那具体是怎么拆任务、怎么配置线程池参数的？

我们这个场景，单个“批量任务”可能包含上万条工单记录。直接一个任务里顺序 for 循环生成，会很慢，而且无法利用多核。

我做了两层拆分：

#### 第一层：按“批量任务”级别做异步

用户前端点击“批量生成工单”，接口里只做三件事：

1. 校验输入参数合法性；
2. 在数据库里插入一条 task 记录（包含任务 ID、状态、总数量、创建人、生成工单的必要信息等）；
3. 异步提交一个“处理该任务”的 Runnable 到线程池，立即返回任务 ID 和“已受理”状态给前端。

这样接口响应时间基本就是“落库 + 提交线程池”的时间，大概几十毫秒到一两百毫秒。

#### 第二层：任务内部按数据分片并行处理

1. 真正处理的时候，不是一个线程把 N 条全部串行处理，而是按页或分片，比如每 200 条为一批，拆成多个子任务；
2. 每个子任务负责处理一小批工单生成与下发，再由线程池并行调度；
3. 处理过程中会把“已处理数量 / 成功数量 / 失败数量”持续回写到任务表里，方便后续查询进度。

#### 线程池参数这块

我们这个“批量生成并下发工单”的任务，其实是**“计算 + IO”混合型**的：

- 计算部分（CPU 密集）：
  - 根据规则生成工单（拆单、分组、费用计算、风控规则校验等等）
  - 做一些数据转换、校验、对象组装
- IO 部分（IO 密集）：
  - 查询数据库、落库
  - 调用下游系统接口(各省提供的)，推送工单

从实际压测来看，这个流程里：

- 单条工单的“规则计算 + 对象组装”耗时大概在 5~10ms；
- 调用下游接口（包括网络 + 下游处理）耗时在 50~200ms 不等。

也就是说：大头是 IO 等待，整体更偏 IO 密集型任务。

在设线程数的时候，我主要参考两个经验公式：

- CPU 密集型：
  - 一般线程数在 N 到 N + 1 左右（N 是 CPU 核数），因为 CPU 基本上是满的，再多线程只会增加上下文切换。
- IO 密集型：
  - 线程数 ≈ CPU 核数 × (1 + 等待时间 / 计算时间)
  - 也就是如果一个线程大部分时间都在等 IO，那可以适当把线程数放大，让 CPU 在别的任务上干活。

我们线上机器是 8 核 CPU，通过压测，我们大概测出一条工单的情况：

- 业务计算部分（不含 IO）平均耗时：≈ 10ms
- 数据库 + 下游接口 IO 平均耗时：≈ 90ms

代入公式：线程数 ≈ 8 × (1 + 90 / 10) = 80

80 只是一个理论上限的参考值，不能直接拿来用。因为线程太多会：

- 增加上下文切换开销；
- 同时也会对数据库和下游接口造成更大压力，可能把对方打挂。

所以我们后面通过压测做了几轮调整：

- 我们分别测了线程数为 16、32、64 的情况；
- 观察几个指标：单任务完成时间、系统 CPU 使用率、下游接口 RT、错误率。

综合下来发现，线程数在 32 左右时：

- CPU 利用率大概在 40% ～ 60%（还有余量）；
- 下游接口 RT 比较稳定，QPS 也在对方能接受的范围内；
- 再往上加线程，整体任务耗时并没有线性下降，反而下游接口的压力会明显变大，错误率升高

所以最后我们是：maximumPoolSize 设在 32。

corePoolSize，我考虑了两点：

1. 机器是 8 核，完全 CPU 密集的话，核心线程大概就是 8 左右；
2. 但这个任务 IO 占比高，而且批量任务高峰时段是明显的（例如每天固定时段集中跑）。

最后我们把：corePoolSize 定在 CPU 核数的 2 倍左右，也就是 16：

- 这样在低负载时不会创建太多线程浪费；
- 一旦有任务积压时，可以通过 maximumPoolSize 往上扩到 32。

对于 队列大小，我们坚持用有界队列，避免堆积任务把内存撑爆。

我们考虑了两个因素：

- 业务上，一个批量任务最多可能包含 1 万条工单；
- 同时在线的“批量任务”数量，我们做了限流，例如同时只允许 10 个批量任务在执行队列中排队，超过就直接拒绝并引导用户稍后再试。

单个线程池里，最多允许的工单任务数量：

- 每个批量任务会拆成若干“小批次子任务”，比如按 200 条/批来分；
- 那 1 万条 ≈ 50 个子任务，也就是说 1 个批量任务会占用 50 个子任务；
- 10 个批量任务同时存在，则理论最大子任务数 ≈ 500。

结合这个上限，我们给线程池配了：LinkedBlockingQueue，容量大概 1000 左右（略大于理论最大值，留一些缓冲）。

### 拒绝策略是怎么选的？

既然我们用了有界队列，就一定会遇到“队列满了”的场景，所以拒绝策略也要选好。

我们一开始尝试过 CallerRunsPolicy，但是：

- 提交任务的是 Web 请求线程，如果它被迫执行任务，会拉长接口响应时间，甚至把 Tomcat 的业务线程都拖慢。

最后我们改成了：AbortPolicy + 业务侧兜底：

- 线程池抛出 RejectedExecutionException；
- 在提交任务那里 catch 这个异常，
- 记录日志 + 打点监控
- 返回给调用方一个“系统繁忙，请稍后再试”的错误码。

批量任务这块，因为本来就是异步的，我们也会把“提交失败”的信息写到任务记录里（状态 = 失败 + 失败原因），方便运营排查。
