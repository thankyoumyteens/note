# 消息队列

## kafka 消息堆积怎么处理

1. 增加消费者数量。增加 topic 的分区数，确保分区数足够多以支持更多的消费者。因为每个分区在同一时间只能被消费者组中的一个消费者消费
2. 将一些耗时的操作（如写入数据库、调用外部服务等）改为异步处理，使用线程池或消息队列来处理这些任务，让消费者可以更快地返回并继续消费下一条消息
3. Kafka 采用消费者拉取（pull）的方式从 broker 获取消息。消费者可以根据自身的处理能力和需求，自主控制拉取消息的速率和数量。如 max.poll.records（每次拉取的最大消息数）和 fetch.max.bytes（每次拉取的最大字节数）。Kafka 的消息是以日志文件的形式存储在磁盘上的, 这意味着大量消息积压时，消息不会全部占用内存，而是以文件形式存储在磁盘。当消费者处理不过来导致消息积压时，减少这些参数的值，让消息更多地停留在磁盘日志中，需要时再拉取处理

## kafka 如何保证消息不丢失

需要从生产者、Broker 以及消费者三个层面进行考虑和配置

- 生产者层面
  - 确认机制(ACK): 生产者发送消息时，可以通过设置 acks 参数来控制消息的确认机制，确保消息成功发送到 Broker。
  - 重试机制: 生产者可以设置 retries 参数来设置最大重试次数, retry.backoff.ms 参数啦设置重试间隔时间。当消息发送失败时，生产者会自动重试发送消息，直到达到最大重试次数
- Broker 层面
  - 多副本机制: 每个主题的分区都可以有多个副本，其中一个是 Leader 副本，负责处理读写请求，其他副本是 Follower 副本，通过与 Leader 副本同步消息来保证数据的一致性。可以通过设置 replication.factor 参数来指定每个分区的副本数
  - 同步副本集合(ISR): ISR 是与 Leader 副本保持同步的 Follower 副本集合。只有在 ISR 中的副本才会参与消息的确认和选举。可以通过设置 min.insync.replicas 参数来指定 ISR 中至少需要多少个副本才能进行消息的写入，确保有足够的副本同步消息，从而提高消息的可靠性
  - 日志刷盘策略: Kafka 的消息是先写入内存缓冲区，然后定期刷盘到磁盘。可以通过调整 log.flush.interval.messages（消息数达到一定数量时刷盘）和 log.flush.interval.ms（时间间隔达到一定值时刷盘）等参数来控制日志刷盘的频率，确保消息及时持久化到磁盘，减少因 Broker 故障导致消息丢失的风险
- 消费者层面
  - 手动提交偏移量: 在手动提交偏移量时，消费者需要在处理完消息后，手动调用 commitSync() 或 commitAsync() 方法来提交当前消费的偏移量

acks 参数的可选值:

- acks = 0：生产者发送消息后，不等待 Broker 的确认，直接认为消息发送成功。这种方式虽然发送速度快，但无法保证消息是否真正到达 Broker，可能会导致消息丢失，因此不建议用于需要保证消息不丢失的场景
- acks = 1：生产者发送消息后，等待 Leader 副本确认收到消息后就认为发送成功。如果 Leader 副本在确认消息后但在将消息同步到 Follower 副本之前发生故障，可能会导致消息丢失
- acks = all 或 acks = -1：生产者发送消息后，等待 Leader 副本和所有 ISR 中的副本都确认收到消息后才认为发送成功。这种方式可以最大程度地保证消息不丢失，但会降低消息的发送性能
