# JWT+RefreshToken

客户端将用户名和密码传给服务端进行登陆，服务端核对成功后将用户信息作为jwt的payload生成有效时间较短的JWT字符串作为AccessToken，并生成有效时间较长的RefreshToken，一起返回给客户端。客户端将其保存，每次请求时都会携带AccessToken，如果AccessToken过期，则客户端使用RefreshToken向刷新接口申请新的AccessToken。退出登录时，删除JWT字符串就可以。

由于RefreshToken不会在客户端请求业务接口时验证，所以将RefreshToken存储在数据库中，不会对业务接口的响应时间造成影响。当用户需要登出或禁用用户时，只需要将服务端的RefreshToken禁用或删除，用户就会在AccessToken过期后无法访问需要认证的接口。这样的方式虽然会有一定的窗口期，但是结合用户登出时客户端删除AccessToken的操作，基本上可以适应常规情况下对用户认证鉴权的精度要求。

# 红黑树和AVL树对比

- 红黑树只保证黑色节点是绝对平衡的，算上红色节点的话平衡因子（节点左右子树的高度差）可能大于1
- 红黑树添加和删除占优势，红黑树只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能
- AVL树查询占优势
- 红黑树增删改查综合性能更好

## 左旋转

x的左节点连接到y，y的右节点连接到x的左节点
```
x.left = y
y.right = T2
   y                 x
  / \              /   \
 T1  x            y     z
    / \          / \   / \
   T2  z        T1 T2 T3 T4
      / \      
     T3 T4     
```

## 右旋转

x的右节点连接到y，y的左节点连接到x的右节点
```
x.right = y
y.left = T3
       y             x
      / \          /   \
     x  T4        z     y
    / \          / \   / \
   z  T3        T1 T2 T3 T4
  / \          
 T1 T2         
```

# 快速排序

选中第一个元素v，调整数组使得左边的元素小于v，中间的元素等于v，右边的元素大于v，使v所在的中间部分将原数组在逻辑上分割为左右两个子数组，
不断重复这个操作，直到分割后的所有子数组长度都等于4，此时排序已经完成

## 调整步骤

- 随机取数组中的一个元素作为V，把V和第一个元素交换，使V成为数组第一个元素
- j指向数组第一个元素V
- k指向数组最后的元素
- i指向数组第二个元素
- 从i开始遍历整个数组
- 把i指向的元素和V比较，如果大于V，就把i指向的元素和k-1指向的元素交换，i不变，k--。如果小于V，就把i指向的元素和j+1指向的元素交换，j++。如果等于V，不做操作
- 以此类推，直到i和k相等。最后把V和j指向的元素交换

# ConcurrentHashMap

## JDK1.7

ConcurrentHashMap由Segment数组组成，每个Segment又包含一个HashEntry数组，数组中的每一个HashEntry既是一个键值对，也是一个链表的头节点。

ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。

ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储（Segment数组），然后给每一段数据配一把锁（ReentrantLock），当一个线程占用锁访问其中一个段的时候，其他段的数据也能被其他线程访问，在保证线程安全的同时降低了锁的粒度，让并发操作效率更高。

![](Java/base/img/cmap1.png)

## JDK1.8

去除Segment+HashEntry的实现，改为Synchronized+CAS+Node数组的实现。用Synchronized+CAS代替Segment，这样锁的粒度更小了，并且不是每次都要加锁，只有CAS尝试失败了再加锁。

Node数组使用来存放树或者链表的头结点，当一个链表中的数量到达一个数目时，会使查询速率降低，所以到达一定阈值时，会将一个链表转换为一个红黑树，提高查询的速率。

# synchronized锁升级的原理

在对象的对象头里有一个ThreadId字段，在第一次被线程访问的时候ThreadId为空，jvm让其持有偏向锁，并将ThreadId设置为访问的线程id。之后有线程再次访问的时候会先判断ThreadId是否与这个线程id一致，如果一致则可以直接使用此对象，如果不一致则升级偏向锁为轻量级锁。访问的线程通过自旋一定次数来获取锁，循环一定次数之后，如果还没有获取到要使用的对象，就会把锁升级为重量级锁。

锁的升级的目的：锁升级是为了降低锁带来的性能消耗。

- 偏向锁: 指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。
- 轻量级锁: 当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。
- 重量级锁: 因为使用自旋的方式非常消耗CPU，当一定时间内通过自旋的方式无法获取到锁，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁，此时等待锁的线程都会进入阻塞状态。
- 自旋: 循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

# 说一下synchronized底层实现原理？

synchronized底层是通过monitor对象的monitorenter和monitorexit指令实现的。在Java 6之前，monitor的实现是依靠操作系统内部的同步原语，需要进行用户态到内核态的切换，所以同步操作的性能很低。但在Java 6的时候，Java虚拟机提供了三种不同的monitor实现：偏向锁、轻量级锁和重量级锁，大大改进了性能。

# Chrome中cookie的容量限制和个数限制

一般是4k，每个域为53个

# 说一下session的工作原理？

客户端完成登录后，服务器会创建对应的session，并把sessionId发送给客户端，客户端再存储到浏览器（不一定是cookie）中。客户端每次访问服务器时，都会带着sessionId，服务器拿到sessionId之后，在内存找到与之对应的session。

# 说一下你熟悉的设计模式？

- 单例模式：保证被创建一次，节省系统开销。
- 工厂模式：解耦代码。
- 观察者模式：定义了对象之间的一对多的依赖，当一个对象改变时，它的所有的依赖者都会收到通知并自动更新。
- 外观模式：提供一个统一的接口，用来访问子系统中的一群接口，外观定义了一个高层的接口，让子系统更容易使用。
- 模版方法模式：定义了一个算法的骨架，而将一些步骤延迟到子类中，模版方法使得子类可以在不改变算法结构的情况下，重新定义算法的步骤。

# 观察者模式

发布者发布信息，订阅者获取信息。定义了对象之间的一对多的依赖，当一个对象改变时，它的所有的依赖者都会收到通知并自动更新。

```java
/**
 * 被观察者接口
 */
public interface Observerable {
    // 订阅
    void registerObserver(Observer o);
    // 取消订阅
    void removeObserver(Observer o);
    // 通知观察者
    void notifyObserver();
}
/**
 * 观察者接口
 * 当被观察者调用notifyObserver()方法时，
 * 观察者的update()方法会被回调。
 */
public interface Observer {
    public void update(String message);
}
/**
 * 被观察者实现
 */
public class WechatServer implements Observerable {
    
    private List<Observer> list = new ArrayList<Observer>();
    private String message;
    
    @Override
    public void registerObserver(Observer o) {
        list.add(o);
    }
    @Override
    public void removeObserver(Observer o) {
        if(!list.isEmpty())
            list.remove(o);
    }
    @Override
    public void notifyObserver() {
        for(Observer oserver : this.list) {
            oserver.update(this.message);
        }
    }
    public void setInfomation(String s) {
        this.message = s;
        // 消息更新，通知所有观察者
        notifyObserver();
    }
}
```

### 应用

围绕购票会产生不同的其他逻辑，如：

1. 购票后记录文本日志
1. 购票后记录数据库日志
1. 购票后发送短信
1. 购票送抵扣卷、兑换卷、积分
1. 其他各类活动等

传统解决方案:

在购票逻辑等类内部增加相关代码，完成各种逻辑。

存在问题：

- 紧密耦合，一旦某个业务逻辑发生改变，如购票业务中增加其他业务逻辑，需要修改购票核心文件、甚至购票流程。
- 日积月累后，文件冗长，导致后续维护困难。

观察者模式典型实现方式：

- 定义2个接口：观察者接口、被观察者接口
- 购票类注册自己需要通知的观察者
- 购票发生时通知观察者对象，每个观察者执行自己的业务逻辑。

# 外观模式

外观模式提供一个统一的接口，用来访问子系统中的一群接口，外观定义了一个高层的接口，让子系统更容易使用。

```java
/**
 * 子系统1
 */
public class DrinkableWater {
    public void getWater(){
        System.out.println("煮水");
    }
}
/**
 * 子系统2
 */
public class Tea {
    public void getTea(){
        System.out.println("取茶");
    }
}
/**
 * 子系统3
 */
public class TeaCup {
    public void getTeaCup(){
        System.out.println("泡茶");
    }
}
/**
 * 外观对象
 */
public class Waiter {
    // 对外的统一接口
    public void getTea(){
        // 内部实现会调用多个子系统
        new DrinkableWater().getWater();
        new TeaCup().getTeaCup();
        new Tea().getTea();
    }
}
/**
 * 客户端
 */
public class Customer {
    public static void main(String[] args) {
        new Waiter().getTea();
    }
}
```

# 模版方法模式

定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。子类可以置换掉父类的可变部分，但是子类却不可以改变模板方法所代表的顶级逻辑。

```java
// 抽象模板类
public abstract class AbstractTemplate {
    // 模板方法, 可以有任意多个
    public void templateMethod(){
        //调用基本方法
        abstractMethod();
        hookMethod();
        concreteMethod();
    }
    // 抽象方法, 由具体子类实现
    protected abstract void abstractMethod();
    // 钩子方法(空方法), 子类可选择实现，不是必须实现
    protected void hookMethod(){}
    // 具体方法, 由抽象类声明并实现
    private final void concreteMethod(){
        System.out.println("do");
    }
}

// 具体模板类，实现了父类所声明的基本方法
public class ConcreteTemplate extends AbstractTemplate{
    // 基本方法的实现
    @Override
    public void abstractMethod() {
        System.out.println("do1");
    }
    // 重写父类的方法
    @Override
    public void hookMethod() {
        System.out.println("do2");
    }
}
```

### 应用

Servlet

HttpServlet是抽象模板
- 由service()方法担任模板方法。
- Servlet并非完全按照模板方法定义的那样，而是做了变通，提供了默认doGet、doPost的实现

自己实现的TestServlet是具体模板
- TestServlet置换掉了父类HttpServlet中七个基本方法中的其中两个，分别是doGet和doPost

# 解释一下什么是aop

aop是面向切面编程，通过动态代理实现统一处理某一类问题的编程思想，比如统一处理日志、异常等。

# 解释一下什么是ioc

由spring来负责控制对象的生命周期和对象间的关系。控制反转指的是，这种控制权不由当前对象管理了，由第三方容器来管理。

# Spring中的事务传播行为

- Propagation.REQUIRED（默认）: 如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。
- Propagation.SUPPORTS: 如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。
- Propagation.MANDATORY: 如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。
- Propagation.REQUIRES_NEW: 重新创建一个新的事务，如果当前存在事务，挂起当前的事务。外层事务不会影响内部事务的提交/回滚，内部事务的异常，会影响外部事务的回滚
- Propagation.NOT_SUPPORTED: 以非事务的方式运行，如果当前存在事务，暂停当前的事务。
- Propagation.NEVER: 以非事务的方式运行，如果当前存在事务，则抛出异常。
- Propagation.NESTED: 如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。

# spring cloud的核心组件有哪些

- Eureka：服务注册与发现。
- Feign：基于动态代理机制，根据注解和选择的机器，拼接url地址，发起请求。
- Ribbon：实现负载均衡，从一个服务的多台机器中选择一台。
- Hystrix：资源隔离，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。断路器机制，当后端服务失败数量超过一定比例，断路器会切换到开路状态. 这时所有请求会直接失败而不会发送到后端服务，断路器有自我检测并恢复的能力。降级操作，当请求后端服务出现异常的时候，可以使用自定义的fallback方法返回的值
- Zuul：网关管理，由Zuul网关转发请求给对应的服务。

# RabbitMQ的使用场景有哪些

- 削峰，在访问量剧增的情况下，防止系统崩塌。
- 延迟消息，把消息发送给MQ，MQ并不立即处理。
- 解耦系统，对于新增的功能可以单独写模块扩展，只需要订阅对应的消息队列即可。

# 消息可靠性投递

## 消息落库方案

1. 业务数据和消息数据入库（此时消息状态为未成功0）后向MQ发送消息。
3. MQ收到消息后，发送确认消息Ack。
4. 生产者接收到服务器发送的确认消息 Ack，修改数据库中消息的状态为成功（1）。
5. 定时任务查询数据库中消息状态为未成功（0）的数据并重新发送。当重新发送的次数，大于一定的值时，修改该条消息状态为发送失败（2）。

## 延迟投递方案

1. 生产者将业务数据入库并向MQ发送消息。
3. 生产者在发送消息的指定时间后发送延迟消息。
4. 消费者对消息进行消费后，向MQ发送确认消息。
6. Callback服务监听消费者发送的确认消息，如果收到消息则对消息状态做投递成功的记录。
7. Callback服务收到生产者的延迟消息后去检查第六步中的记录，如果没有记录，则通知上游服务再次发送消息。
8. 这种方案不一定能保障百分百投递成功，主要目的是为了减少数据库操作，提高并发量。

# MQ消息积压怎么处理

1. 临时将queue资源和consumer资源扩大10倍，以正常速度的10倍来消费消息。新增原先数量10倍的queue，将现有consumer都停掉，用一个临时分发消息的consumer，消费之后不做耗时处理，直接均匀轮询写入临时建好分10倍数量的queue里面。等快速消费完了之后，恢复原来的部署架构，重新用原来的consumer机器来消费消息。
2. 临时写个程序，连接到mq里面消费数据，收到消息之后直接将其丢弃，快速消费掉积压的消息，降低MQ的压力，然后在晚上夜深人静时去手动查询重导丢失的这部分数据。

# 说一下MySQL常用的引擎

- InnoDB：mysql 5.1后默认的数据库引擎，提供了事务的支持，并且还提供了行级锁和外键的约束。不支持全文搜索，它不会保存表的行数，所以当进行select count(*)时，需要进行扫描全表。由于锁的粒度小，写操作不会锁定全表，所以在并发度较高的场景下使用会提升效率。
- MyISAM：不提供事务的支持，也不支持行级锁和外键。因此当执行写操作的时候需要锁定整个表，所以效率较低。不过MyISAM保存了表的行数，所以当进行select count(*)时，可以直接读取而不需要进行扫描全表。所以，如果表的读操作远远多于写操作时，并且不需要事务的支持，可以将MyISAM作为数据库引擎的首选。

# 数据库的事务隔离级别

- READ_UNCOMMITTED：未提交读，事务未提交前，就可被其他事务读取（会出现幻读、脏读、不可重复读）。
- READ_COMMITTED：已提交读，事务提交后才能被其他事务读取到（会造成幻读、不可重复读）。
- REPEATABLE_READ（MySQL默认）：可重复读，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止读取到别的事务未提交的数据（会造成幻读）。
- SERIALIZABLE：序列化，一个个事务排成序列的形式。事务一个挨一个执行，等待前一个事务执行完，后面的事务才可以顺序执行。代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。

- 脏读：表示一个事务读到了另一个事务中还未提交或回滚的数据。
- 不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了。
- 幻读：当前事务第一次取到的数据和后来读取到数据条目不同。比如事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。

# 如何做MySQL的性能优化

- 为搜索字段创建索引。
- 尽量使用多表连接查询，避免子查询
- 避免使用select *，列出需要查询的字段。
- 垂直分割分表，并选择正确的存储引擎。

# 主键索引和普通索引区别

- 普通索引是最基本的索引类型，没有任何限制，值可以为空，仅加速查询。普通索引是可以重复的，一个表中可以有多个普通索引。
- 主键索引是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值；索引列的所有值必须唯一。

# 说一下乐观锁和悲观锁

- 乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。
- 悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻止，直到这个锁被释放。

# Redis持久化有几种方式

- RDB（Redis Database）：指定的时间间隔能对你的数据进行快照存储。
- AOF（Append Only File）：每一个收到的写命令都通过write函数追加到文件中。

# Redis数据类型

string（字符串）、list（列表）、hash（字典）、set（集合）、zset（有序集合）。

# Redis缓存穿透缓存击穿缓存雪崩

- 缓存穿透: 用户不断请求缓存和数据库中都没有的数据，导致数据库压力过大。解决方案: 将数据库中没有取到的key缓存为null
- 缓存击穿: 用户大量请求缓存中没有但数据库中有的数据（一般是缓存时间到期），导致数据库压力过大。解决方案: 1、直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。2、加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，等到第一个线程将数据写入缓存后，其他的线程直接走缓存。
- 缓存雪崩: 缓存中不同的数据大批过期，导致数据库压力过大。解决方案: 1、过期时间设置随机。2、设置热点数据永远不过期。

# Redis清除过期Key的方式

- 定时检查删除：对于每一个设置了过期时间的key都会创建一个定时器，一旦达到过期时间会直接删除。这种方式立即清除过期数据，对内存比较好，但是占用了大量CPU的资源去处理过期数据，会影响redis的吞吐量和响应时间。
- 惰性检查删除：当访问一个key的时候，才会判断该key是否过期，如果过期就删除。该方式能最大限度节省 CPU 的资源。但是会占用较多的内存。
- 定期检查删除：每隔一段时间，就对部分key进行检查，删除里面过期的key。可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响。定期删除也能有效释放过期key占用的内存，但是难以确定删除操作执行的时长和频率。可以通过修改配置文件redis.conf的hz选项来调整这个次数。

Redis的过期删除策略是：惰性删除和定期删除两种策略配合使用。

# Redis内存淘汰机制

- no-eviction：当内存不足以容纳新写入数据时，新的写入操作会报错
- allkeys-lru：当内存不足以容纳新写入数据时，移除最近最少使用的key（这个是最常用的）
- allkeys-random：当内存不足以容纳新写入数据时，随机移除某个key
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的key中，移除最近最少使用的key
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的key中，随机移除某个key
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，有更早过期时间的key优先移除

# Redis为什么并发性能高

- redis是基于内存的，内存的读写速度非常快
- redis是单线程的，省去了切换线程的时间，不存在加锁释放锁操作
- 使用多路复用技术，非阻塞IO



> ---分割线---



# 接口幂等性

接口任意多次调用所产生的影响均与一次调用的影响相同。

实现接口幂等性

1. 防重Token: 请求前先向后端请求一个全局ID，请求时携带这个全局ID，后端用这个ID到Redis中进行校验，如果存在就删除这个ID；如果不存在就是重复执行。
2. 调用方传递唯一ID: 请求时携带一个短时间内唯一的ID，服务器收到请求后拿该ID到Redis中查询是否存在，如果存在就是重复执行；如果不存在就把这个ID存储到Redis中。
3. 数据库乐观锁: 在对应的表中多添加一个版本号字段。每次调用都会传递版本号，并将该版本号作为where条件，如果重复执行SQL语句，会因为版本不一致而不生效。

# 如何将字符串反转？

使用StringBuilder的reverse()方法。

或者对撞指针
```java
String reverseString(String str) {
    char [] s = str.toCharArray();
    int l = 0;
    int r = s.length - 1;
    while (l < r) {
        swap(s, l++, r--);
    }
    return new String(s);
}
void swap(char[] arr, int i, int j){
    char t = arr[i];
    arr[i] = arr[j];
    arr[j] = t;
}
```

# String str="i"与 String str=new String("i")一样吗

不一样，因为内存的分配方式不一样。`String str="i"`的方式，Java虚拟机会将其分配到常量池中（常量池保存在方法区中），`String str=new String("i")`则会被分配到堆中。

# synchronized 和 volatile 的区别是什么？

- volatile修饰变量。synchronized修饰类、方法、代码段。
- volatile仅能实现变量的修改可见性，不能保证原子性。synchronized可以保证变量的修改可见性和原子性。
- volatile不会造成线程的阻塞。synchronized可能会造成线程的阻塞。

## 变量的修改可见性

Java 内存模型规定所有的共享变量都存储于主内存。每一个线程还存在自己的工作内存，保留了被线程使用的变量的副本。线程对变量的所有的操作都必须在工作内存中完成，而不能直接读写主内存中的变量。不同线程之间也不能直接访问对方工作内存中的变量，线程间变量的值的传递需要通过主内存中转来完成。所以可能会导致线程对共享变量的修改没有即时更新到主内存，从而使得线程在使用共享变量的值时，该值并不是最新的。

当一个线程进入synchronized代码块后，线程获取到锁，会清空工作内存，然后从主内存中拷贝共享变量的最新值到工作内存作为副本，执行代码，又将修改后的副本值刷新到主内存中，最后线程释放锁。除了synchronized外，其它锁也能保证变量的内存可见性。

使用volatile修饰共享变量后，当线程操作变量副本并写回主内存后，会通过CPU总线嗅探机制告知其他线程该变量副本已经失效，需要重新从主内存中读取。

# synchronized 和 lock 有什么区别？

- synchronized可以给类、方法、代码块加锁。而lock只能给代码块加锁。
- synchronized不需要手动获取锁和释放锁，发生异常会自动释放锁，不会造成死锁。而lock需要自己加锁和释放锁，如果没有释放锁就可能造成死锁。
- 通过lock可以知道有没有成功获取锁，而synchronized不能。

# 什么是死锁

当线程A持有独占锁a，并尝试去获取独占锁b的同时，线程B持有独占锁b，并尝试获取独占锁a的情况下，就会发生A、B两个线程由于互相持有对方需要的锁，而发生的阻塞现象，称为死锁。

# 怎么防止死锁

- 尽量使用Lock接口的`tryLock(long time, TimeUnit unit)`方法，设置超时时间。
- 尽量使用`java.util.concurrent`中的并发类代替自己手写锁。
- 尽量降低锁的使用粒度，尽量不要几个功能用同一把锁。
- 尽量减少同步的代码块。

# 如何避免 SQL 注入？

- 使用PreparedStatement。
- 使用正则表达式过滤掉特殊字符。

# 什么是 XSS 攻击，如何避免？

跨站脚本攻击，攻击者往Web页面里插入恶意的脚本代码，当用户浏览该页面时，嵌入其中的脚本代码会被执行，从而达到恶意攻击用户的目的，如盗取用户 cookie、破坏页面结构、重定向到其他网站等。

预防XSS的核心是必须对输入的数据做过滤处理。

# 什么是 CSRF 攻击，如何避免？

跨站请求伪造，攻击者盗用了用户的身份来发送恶意请求。

用户登录了A网站，认证信息保存在cookie中。在用户未退出网站A之前，在同一浏览器中，打开一个TAB页访问攻击者创建的B网站时，攻击者通过在B网站发送一个伪造的请求提交到A网站服务器上，此时浏览器会自动携带cookie访问A网站的这个地址，A网站的服务器就会误以为请求来自于自己的网站。

防御手段：

- 验证请求来源地址。
- 关键操作添加验证码。
- 在请求添加token并验证。

# MyBatis的一级缓存和二级缓存

- 一级缓存：HashMap本地缓存，它的生命周期是和SQLSession一致的，有多个SQLSession或者分布式的环境中数据库操作，可能会出现脏数据。当Session flush或close之后，该Session中的所有Cache就将清空，默认一级缓存是开启的。
- 二级缓存：也是HashMap本地缓存，不同在于其存储作用域为Mapper级别的，如果多个SQLSession之间需要共享缓存，则需要使用到二级缓存，并且二级缓存可自定义存储源，如redis。默认不打开二级缓存，要开启二级缓存，使用二级缓存需要实现Serializable序列化接口。

# MyBatis延迟加载的原理是什么

调用的时候触发加载，而不是在初始化的时候就加载信息。比如调用a.getB()时发现a.getB()的值为null，此时会单独触发事先保存好的关联B对象的SQL，先查询出来B，然后再调用a.setB(b)，而这时候再调用a.getB()就有值了。

# RabbitMQ 怎么实现延迟消息队列

- rabbitmq_delayed_message_exchange插件
- DLX（死信交换机）+TTL（消息超时时间）实现延迟队列。假如一条消息需要延迟30分钟执行，就设置这条消息的有效期为30分钟，同时为这条消息配置死信交换机和死信routing_key，并且不为这个消息队列设置消费者，那么30分钟后，这条消息由于没有被消费者消费而进入死信队列，消息一进入死信队列，就会被监听这个死信队列的消费者消费了。

# RabbitMQ的消息模型

## 基本消息模型

![](Java/RabbitMQ/img/2.png)

生产者向消息队列中投递消息，消费者从其中取出消息。 

## work消息模型

![](Java/RabbitMQ/img/3.png)

两个消费者共同消费同一个队列中的消息，但是一个消息只能被一个消费者获取。work模型通过手动确认机制实现能者多劳

## 发布-订阅模型 Fanout(广播)

![](Java/RabbitMQ/img/4.png)

广播模式有多个消费者，每个消费者有自己的队列，生产者发送的消息，只能发送到交换机，交换机把消息发送给绑定的所有队列，实现一条消息被多个消费者消费

## 发布-订阅模型 Direct

![](Java/RabbitMQ/img/5.png)

生产者向交换机发送消息时，会指定一个routing key。交换机把生产者的消息交给与routing key完全匹配的队列

## 发布-订阅模型 Topic

![](Java/RabbitMQ/img/6.png)

Topic类型的Exchange与Direct相比，都是可以根据RoutingKey把消息路由到不同的队列。只不过Topic类型Exchange可以让队列在绑定Routing key 的时候使用通配符，`#`匹配一个或多个词，`*`匹配一个词

# B+树

## 一个m阶的B+树具有如下几个特征

- 中间节点中的每个元素都有且只有一个子节点。
- 中间节点不保存数据，只用来索引，所有数据都保存在叶子节点。
- 所有的中间节点的元素都同时存在于其子节点，是子节点中的最大元素。
- 所有的叶子节点中包含了全部元素的信息，且叶子节点本身依元素的大小顺序链接，形成了一个有序链表。
- 根节点的最大元素也是整个B+树的最大元素。

![](Algorithm/img/bpt1.png)

## 查询单个元素

![](Algorithm/img/bpt2.png)

查询 59

- 访问根节点`[59,97]`，发现 59 小于等于`[59,97]`中的 59 ，则访问根节点的第一个子节点
- 访问节点`[15,44,59]`，发现 59 大于 44 且小于等于 59 ，则访问当前节点的第三个子节点
- 访问叶子节点`[51,59]`，顺序遍历节点内部，找到要查找的元素 59

## 查询区间

![](Algorithm/img/bpt2.png)

查询区间`[21~63]`

- 访问根节点`[59,97]`, 发现区间的左端点 21 小于 59，则访问第一个子节点
- 访问节点`[15,44,59]`，发现 21 大于 15 且小于 44 ，则访问第二个子节点
- 访问节点`[21,37,44]`，找到了左端点 21 ，此时只需要进行单链表的遍历，直接从左端点 21 开始一直遍历到右端点 63 即可

## 插入

设B+树的阶数 M = 3

### 情况1

若被插入元素所在的节点，其含有元素数小于阶数 M，则直接插入

![](Algorithm/img/bpt3.png)

插入元素12 ，按查找的步骤找到要插入的节点，插入元素所在的节点的`[10,15]`包含2个元素，小于3，则直接插入元素12

### 情况2

若插入元素所在的节点，其含有元素数目等于阶数M，则需要将该节点分裂为两个节点，左节点包含（`ceil(M/2)`）个元素，右节点包含（`floor(M/2)`）个元素。同时，将左节点的最大元素上移至其父节点。假设其父节点中包含的元素个数小于等于M，则插入操作完成。

![](Algorithm/img/bpt4.png)

插入元素95，插入元素所在节点`[85,91,97]`包含元素个数3等于阶数M，需要分裂，将元素95插入到节点`[85,91,97]`中，将`[85,91,95,97]`分裂为两个节点`[85,91]`和节点`[95,97]`，并将左节点的最大元素91上移至其父节点中，发现其父节点`[72,97]`中包含的元素的个数2小于阶数M，插入操作完成。

### 情况3

在情况2中，如果上移操作导致其双亲节点中元素个数大于M，则应继续分裂其双亲节点。

![](Algorithm/img/bpt5.png)

插入元素40，按照第2种情况将节点分裂，并将元素37上移到父节点，发现父节点`[15,44,59]`包含的元素的个数等于M ，所以将插入37后的节点`[15,37,44,59]`分裂为两个节点`[15,37]`和节点`[44,59]`，并将左节点的最大元素37上移到父节点`[59,97]`中. 父节点`[59,97]`包含元素个数2小于M，插入结束。

### 情况4

若插入的元素比当前节点中的最大值还大，破坏了B+树中从根节点到当前节点的所有索引值，此时需要修正后，再做其他操作。

![](Algorithm/img/bpt6.png)

插入元素100，由于其值比最大值97还大，插入之后，从根节点到该节点经过的所有节点中的所有值都要由97改为100。改完之后再做分裂操作。

## 删除

设B+树的阶数 M = 3

### 情况1

找到要删除的元素所在的节点时，如果该节点中元素个数大于`ceil(M/2)`，删除操作不会破坏B+树的结构，则可以直接删除。

![](Algorithm/img/bpt7.png)

删除元素 91，包含91的节点 `[85,91,97]`中元素的个数3大于2（`ceil(M/2)`），做删除操作不会破坏 B+树的特性，直接删除。

### 情况2

当删除某节点中最大或者最小的元素，就会涉及到更改其双亲节点一直到根节点中所有索引值的更改。

![](Algorithm/img/bpt8.png)

以删除整颗 B+树中最大的元素97为例，查找并删除元素97，然后向上回溯，将所有元素97替换为次最大的元素91

### 情况3

当删除该元素导致当前节点中元素个数小于`M/2`时，若其兄弟节点中含有多余的元素，可以从兄弟节点中借元素完成删除操作。

![](Algorithm/img/bpt9.png)

删除元素51，由于其左兄弟节点`[21,37,44]`中含有3个元素，所以可以选择借最大的元素44，同时将父节点中的索引值44修改成37

### 情况4

第3种情况中，如果其兄弟节点没有多余的元素，则需要同其兄弟节点进行合并。

![](Algorithm/img/bpt10.png)

删除元素59，首先找到元素59所在节点`[44,59]`，发现该节点的兄弟节点`[21,37]`包含的元素个数等于2（`ceil(M/2)`），所以删除元素59后，将节点`[21,37]`和`[44]`进行合并，然后向上回溯，将所有元素59替换为次最大的元素44

### 情况5

当进行合并时，可能会产生因合并使其父节点破坏B+树的结构，需要依照以上规律处理其父节点。

![](Algorithm/img/bpt11.png)

删除元素63，当删除元素后，该节点中只剩元素72，且其兄弟节点`[85,91]`中只有2个元素，所以将`[72]`和`[85,91]`进行合并，向上回溯，删除节点`[72,91]`当中的元素72，此时节点中只有元素91，不满足B+树中节点元素个数要求，但其兄弟节点`[15,44,59]`中包含3个元素，所以从其兄弟节点当中借一个元素59，再对其兄弟节点的父节点中的元素进行调整，将元素59替换为44


# mysql水平切割和垂直切割

- 纵向分表: 将本来可以在同一个表的字段，人为划分成多个表。变化频率慢、查询次数多的数据使用MyISAM，可以有更好的查询速度。变化频率比较高的数据使用InnoDB，可以有更好的更新速度。 
- 横向分表: 如用户信息表分成user_1,user_2等。根据数据量的规模来划分，保证单表的容量不会太大，从而来保证单表的查询等处理能力。

# spring中的bean是线程安全的吗

spring并没有对bean做线程安全的处理，但是大部分时候bean不会保存数据，所以某种程度上来说bean也是安全的。但如果bean保存了数据的话（比如 view model对象），那就要开发者自己去保证线程安全，最简单的就是把bean的作用域从singleton变为prototype，这样请求bean相当于new Bean()，所以就可以保证线程安全。

# Redis为什么是单线程的

因为cpu不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且cpu又不会成为瓶颈，那就顺理成章地采用单线程的方案了。
