# JWT+RefreshToken

客户端将用户名和密码传给服务端进行登陆，服务端核对成功后将用户信息作为jwt的payload生成有效时间较短的JWT字符串作为AccessToken，并生成有效时间较长的RefreshToken，一起返回给客户端。客户端将其保存，每次请求时都会携带AccessToken，如果AccessToken过期，则客户端使用RefreshToken向刷新接口申请新的AccessToken。退出登录时，删除JWT字符串就可以。

由于RefreshToken不会在客户端请求业务接口时验证，所以将RefreshToken存储在数据库中，不会对业务接口的响应时间造成影响。当用户需要登出或禁用用户时，只需要将服务端的RefreshToken禁用或删除，用户就会在AccessToken过期后无法访问需要认证的接口。这样的方式虽然会有一定的窗口期，但是结合用户登出时客户端删除AccessToken的操作，基本上可以适应常规情况下对用户认证鉴权的精度要求。

# 红黑树和AVL树对比

- 红黑树只保证黑色节点是绝对平衡的，算上红色节点的话平衡因子（节点左右子树的高度差）可能大于1
- 红黑树添加和删除占优势，红黑树只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能
- AVL树查询占优势
- 红黑树增删改查综合性能更好

## 左旋转

x的左节点连接到y，y的右节点连接到x的左节点
```
x.left = y
y.right = T2
   y                 x
  / \              /   \
 T1  x            y     z
    / \          / \   / \
   T2  z        T1 T2 T3 T4
      / \      
     T3 T4     
```

## 右旋转

x的右节点连接到y，y的左节点连接到x的右节点
```
x.right = y
y.left = T3
       y             x
      / \          /   \
     x  T4        z     y
    / \          / \   / \
   z  T3        T1 T2 T3 T4
  / \          
 T1 T2         
```

# 快速排序

选中第一个元素v，调整数组使得左边的元素小于v，中间的元素等于v，右边的元素大于v，使v所在的中间部分将原数组在逻辑上分割为左右两个子数组，
不断重复这个操作，直到分割后的所有子数组长度都等于4，此时排序已经完成

## 调整步骤

- 随机取数组中的一个元素作为V，把V和第一个元素交换，使V成为数组第一个元素
- j指向数组第一个元素V
- k指向数组最后的元素
- i指向数组第二个元素
- 从i开始遍历整个数组
- 把i指向的元素和V比较，如果大于V，就把i指向的元素和k-1指向的元素交换，i不变，k--。如果小于V，就把i指向的元素和j+1指向的元素交换，i++，j++。如果等于V，不做操作
- 以此类推，直到i和k相等。最后把V和j指向的元素交换

# ConcurrentHashMap

## JDK1.7

ConcurrentHashMap由Segment数组组成，每个Segment又包含一个HashEntry数组，数组中的每一个HashEntry既是一个键值对，也是一个链表的头节点。

ConcurrentHashMap定位一个元素的过程需要进行两次Hash操作。第一次Hash定位到Segment，第二次Hash定位到元素所在的链表的头部。

ConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储（Segment数组），然后给每一段数据配一把锁（ReentrantLock），当一个线程占用锁访问其中一个段的时候，其他段的数据也能被其他线程访问，在保证线程安全的同时降低了锁的粒度，让并发操作效率更高。

![](Java/base/img/cmap1.png)

## JDK1.8

去除Segment+HashEntry的实现，改为Synchronized+CAS+Node数组的实现。用Synchronized+CAS代替Segment，这样锁的粒度更小了，并且不是每次都要加锁，只有CAS尝试失败了再加锁。

Node数组使用来存放树或者链表的头结点，当一个链表中的数量到达一个数目时，会使查询速率降低，所以到达一定阈值时，会将一个链表转换为一个红黑树，提高查询的速率。

# synchronized锁升级的原理

在对象的对象头里有一个ThreadId字段，在第一次被线程访问的时候ThreadId为空，jvm让其持有偏向锁，并将ThreadId设置为访问的线程id。之后有线程再次访问的时候会先判断ThreadId是否与这个线程id一致，如果一致则可以直接使用此对象，如果不一致则升级偏向锁为轻量级锁。访问的线程通过自旋一定次数来获取锁，循环一定次数之后，如果还没有获取到要使用的对象，就会把锁升级为重量级锁。

锁的升级的目的：锁升级是为了降低锁带来的性能消耗。

- 偏向锁: 指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。
- 轻量级锁: 当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。
- 重量级锁: 因为使用自旋的方式非常消耗CPU，当一定时间内通过自旋的方式无法获取到锁，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁，此时等待锁的线程都会进入阻塞状态。
- 自旋: 循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。

# 说一下synchronized底层实现原理？

synchronized底层是通过monitor对象的monitorenter和monitorexit指令实现的。在Java 6之前，monitor的实现是依靠操作系统内部的同步原语，需要进行用户态到内核态的切换，所以同步操作的性能很低。但在Java 6的时候，Java虚拟机提供了三种不同的monitor实现：偏向锁、轻量级锁和重量级锁，大大改进了性能。

# Chrome中cookie的容量限制和个数限制

一般是4k，每个域为53个

# 说一下你熟悉的设计模式？

- 单例模式：保证被创建一次，节省系统开销。
- 工厂模式：解耦代码。
- 观察者模式：定义了对象之间的一对多的依赖，当一个对象改变时，它的所有的依赖者都会收到通知并自动更新。
- 外观模式：提供一个统一的接口，用来访问子系统中的一群接口，外观定义了一个高层的接口，让子系统更容易使用。
- 模版方法模式：定义了一个算法的骨架，而将一些步骤延迟到子类中，模版方法使得子类可以在不改变算法结构的情况下，重新定义算法的步骤。应用：Servlet。

# 解释一下什么是aop

aop是面向切面编程，通过动态代理实现统一处理某一类问题的编程思想，比如统一处理日志、异常等。

# 解释一下什么是ioc

由spring来负责控制对象的生命周期和对象间的关系。控制反转指的是，这种控制权不由当前对象管理了，由第三方容器来管理。

# Spring中的事务传播行为

- Propagation.REQUIRED（默认）: 如果当前存在事务，则加入该事务，如果当前不存在事务，则创建一个新的事务。
- Propagation.SUPPORTS: 如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行。
- Propagation.MANDATORY: 如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常。
- Propagation.REQUIRES_NEW: 重新创建一个新的事务，如果当前存在事务，挂起当前的事务。外层事务不会影响内部事务的提交/回滚，内部事务的异常，会影响外部事务的回滚
- Propagation.NOT_SUPPORTED: 以非事务的方式运行，如果当前存在事务，暂停当前的事务。
- Propagation.NEVER: 以非事务的方式运行，如果当前存在事务，则抛出异常。
- Propagation.NESTED: 如果没有，就新建一个事务；如果有，就在当前事务中嵌套其他事务。

# spring cloud的核心组件有哪些

- Eureka：服务注册与发现。
- Feign：基于动态代理机制，根据注解和选择的机器，拼接url地址，发起请求。
- Ribbon：实现负载均衡，从一个服务的多台机器中选择一台。
- Hystrix：资源隔离，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。断路器机制，当后端服务失败数量超过一定比例，断路器会切换到开路状态. 这时所有请求会直接失败而不会发送到后端服务，断路器有自我检测并恢复的能力。降级操作，当请求后端服务出现异常的时候，可以使用自定义的fallback方法返回的值
- Zuul：网关管理，由Zuul网关转发请求给对应的服务。

# RabbitMQ的使用场景有哪些

- 削峰，在访问量剧增的情况下，防止系统崩塌。
- 延迟消息，把消息发送给MQ，MQ并不立即处理。
- 解耦系统，对于新增的功能可以单独写模块扩展，只需要订阅对应的消息队列即可。

# 消息可靠性投递

## 消息落库方案

1. 业务数据和消息数据入库（此时消息状态为未成功0）后向MQ发送消息。
3. MQ收到消息后，发送确认消息Ack。
4. 生产者接收到服务器发送的确认消息 Ack，修改数据库中消息的状态为成功（1）。
5. 定时任务查询数据库中消息状态为未成功（0）的数据并重新发送。当重新发送的次数，大于一定的值时，修改该条消息状态为发送失败（2）。

## 延迟投递方案

1. 生产者将业务数据入库并向MQ发送消息。
3. 生产者在发送消息的指定时间后发送延迟消息。
4. 消费者对消息进行消费后，向MQ发送确认消息。
6. Callback服务监听消费者发送的确认消息，如果收到消息则对消息状态做投递成功的记录。
7. Callback服务收到生产者的延迟消息后去检查第六步中的记录，如果没有记录，则通知上游服务再次发送消息。
8. 这种方案不一定能保障百分百投递成功，主要目的是为了减少数据库操作，提高并发量。

# MQ消息积压怎么处理

1. 临时将queue资源和consumer资源扩大10倍，以正常速度的10倍来消费消息。新增原先数量10倍的queue，将现有consumer都停掉，用一个临时分发消息的consumer，消费之后不做耗时处理，直接均匀轮询写入临时建好分10倍数量的queue里面。等快速消费完了之后，恢复原来的部署架构，重新用原来的consumer机器来消费消息。
2. 临时写个程序，连接到mq里面消费数据，收到消息之后直接将其丢弃，快速消费掉积压的消息，降低MQ的压力，然后在晚上夜深人静时去手动查询重导丢失的这部分数据。

# 说一下MySQL常用的引擎

- InnoDB：mysql 5.1后默认的数据库引擎，提供了事务的支持，并且还提供了行级锁和外键的约束。不支持全文搜索，它不会保存表的行数，所以当进行select count(*)时，需要进行扫描全表。由于锁的粒度小，写操作不会锁定全表，所以在并发度较高的场景下使用会提升效率。
- MyISAM：不提供事务的支持，也不支持行级锁和外键。因此当执行写操作的时候需要锁定整个表，所以效率较低。不过MyISAM保存了表的行数，所以当进行select count(*)时，可以直接读取而不需要进行扫描全表。所以，如果表的读操作远远多于写操作时，并且不需要事务的支持，可以将MyISAM作为数据库引擎的首选。

# 数据库的事务隔离级别

- READ_UNCOMMITTED：未提交读，事务未提交前，就可被其他事务读取（会出现幻读、脏读、不可重复读）。
- READ_COMMITTED：已提交读，事务提交后才能被其他事务读取到（会造成幻读、不可重复读）。
- REPEATABLE_READ（MySQL默认）：可重复读，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止读取到别的事务未提交的数据（会造成幻读）。
- SERIALIZABLE：序列化，一个个事务排成序列的形式。事务一个挨一个执行，等待前一个事务执行完，后面的事务才可以顺序执行。代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。

- 脏读：表示一个事务读到了另一个事务中还未提交或回滚的数据。
- 不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了。
- 幻读：当前事务第一次取到的数据和后来读取到数据条目不同。比如事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。

# 如何做MySQL的性能优化

- 为搜索字段创建索引。
- 尽量使用多表连接查询，避免子查询
- 避免使用select *，列出需要查询的字段。
- 垂直分割分表，并选择正确的存储引擎。

# 主键索引和普通索引区别

- 普通索引是最基本的索引类型，没有任何限制，值可以为空，仅加速查询。普通索引是可以重复的，一个表中可以有多个普通索引。
- 主键索引是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值；索引列的所有值必须唯一。

# 说一下乐观锁和悲观锁

- 乐观锁：每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。
- 悲观锁：每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻止，直到这个锁被释放。

# Redis持久化有几种方式

- RDB（Redis Database）：指定的时间间隔能对你的数据进行快照存储。
- AOF（Append Only File）：每一个收到的写命令都通过write函数追加到文件中。

# Redis数据类型

string（字符串）、list（列表）、hash（字典）、set（集合）、zset（有序集合）。

# Redis缓存穿透缓存击穿缓存雪崩

- 缓存穿透: 用户不断请求缓存和数据库中都没有的数据，导致数据库压力过大。解决方案: 将数据库中没有取到的key缓存为null
- 缓存击穿: 用户大量请求缓存中没有但数据库中有的数据（一般是缓存时间到期），导致数据库压力过大。解决方案: 1、直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。2、加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，等到第一个线程将数据写入缓存后，其他的线程直接走缓存。
- 缓存雪崩: 缓存中不同的数据大批过期，导致数据库压力过大。解决方案: 1、过期时间设置随机。2、设置热点数据永远不过期。

# Redis清除过期Key的方式

- 定时检查删除：对于每一个设置了过期时间的key都会创建一个定时器，一旦达到过期时间会直接删除。这种方式立即清除过期数据，对内存比较好，但是占用了大量CPU的资源去处理过期数据，会影响redis的吞吐量和响应时间。
- 惰性检查删除：当访问一个key的时候，才会判断该key是否过期，如果过期就删除。该方式能最大限度节省 CPU 的资源。但是会占用较多的内存。
- 定期检查删除：每隔一段时间，就对部分key进行检查，删除里面过期的key。可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响。定期删除也能有效释放过期key占用的内存，但是难以确定删除操作执行的时长和频率。可以通过修改配置文件redis.conf的hz选项来调整这个次数。

Redis的过期删除策略是：惰性删除和定期删除两种策略配合使用。

# Redis内存淘汰机制

- no-eviction：当内存不足以容纳新写入数据时，新的写入操作会报错
- allkeys-lru：当内存不足以容纳新写入数据时，移除最近最少使用的key（这个是最常用的）
- allkeys-random：当内存不足以容纳新写入数据时，随机移除某个key
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的key中，移除最近最少使用的key
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的key中，随机移除某个key
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的key中，有更早过期时间的key优先移除

# Redis为什么并发性能高

- redis是基于内存的，内存的读写速度非常快
- redis是单线程的，省去了切换线程的时间，不存在加锁释放锁操作
- 使用多路复用技术，非阻塞IO
